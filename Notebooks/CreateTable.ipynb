{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "BASE_DIR = \"/s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous/obst/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections.abc import MutableMapping\n",
    "\n",
    "def flatten_dict(d: MutableMapping, parent_key: str = '', sep: str ='.') -> MutableMapping:\n",
    "    items = []\n",
    "    for k, v in d.items():\n",
    "        new_key = parent_key + sep + k if parent_key else k\n",
    "        if isinstance(v, MutableMapping):\n",
    "            items.extend(flatten_dict(v, new_key, sep=sep).items())\n",
    "        else:\n",
    "            if type(v) == list:\n",
    "                v = str(v)\n",
    "            items.append((new_key, v))\n",
    "    return dict(items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray.rllib.agents.ddpg.td3 import TD3Trainer\n",
    "default_tde_config = TD3Trainer.get_default_config()\n",
    "default_tde_config = flatten_dict(default_tde_config)\n",
    "\n",
    "from ray.rllib.agents.ppo.ppo import PPOTrainer\n",
    "default_ppo_config = PPOTrainer.get_default_config()\n",
    "default_ppo_config = flatten_dict(default_ppo_config)\n",
    "\n",
    "from ray.rllib.agents.sac.sac import SACTrainer\n",
    "default_sac_config = SACTrainer.get_default_config()\n",
    "default_sac_config = flatten_dict(default_sac_config)\n",
    "\n",
    "from ray.rllib.agents.a3c.a3c import A3CTrainer\n",
    "default_a3c_config = A3CTrainer.get_default_config()\n",
    "default_a3c_config = flatten_dict(default_a3c_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'num_workers': 0,\n",
       " 'num_envs_per_worker': 1,\n",
       " 'create_env_on_driver': False,\n",
       " 'rollout_fragment_length': 1,\n",
       " 'batch_mode': 'truncate_episodes',\n",
       " 'gamma': 0.99,\n",
       " 'lr': 0.0001,\n",
       " 'train_batch_size': 100,\n",
       " 'model._use_default_native_models': False,\n",
       " 'model._disable_preprocessor_api': False,\n",
       " 'model.fcnet_hiddens': '[256, 256]',\n",
       " 'model.fcnet_activation': 'tanh',\n",
       " 'model.conv_filters': None,\n",
       " 'model.conv_activation': 'relu',\n",
       " 'model.post_fcnet_hiddens': '[]',\n",
       " 'model.post_fcnet_activation': 'relu',\n",
       " 'model.free_log_std': False,\n",
       " 'model.no_final_linear': False,\n",
       " 'model.vf_share_layers': True,\n",
       " 'model.use_lstm': False,\n",
       " 'model.max_seq_len': 20,\n",
       " 'model.lstm_cell_size': 256,\n",
       " 'model.lstm_use_prev_action': False,\n",
       " 'model.lstm_use_prev_reward': False,\n",
       " 'model._time_major': False,\n",
       " 'model.use_attention': False,\n",
       " 'model.attention_num_transformer_units': 1,\n",
       " 'model.attention_dim': 64,\n",
       " 'model.attention_num_heads': 1,\n",
       " 'model.attention_head_dim': 32,\n",
       " 'model.attention_memory_inference': 50,\n",
       " 'model.attention_memory_training': 50,\n",
       " 'model.attention_position_wise_mlp_dim': 32,\n",
       " 'model.attention_init_gru_gate_bias': 2.0,\n",
       " 'model.attention_use_n_prev_actions': 0,\n",
       " 'model.attention_use_n_prev_rewards': 0,\n",
       " 'model.framestack': True,\n",
       " 'model.dim': 84,\n",
       " 'model.grayscale': False,\n",
       " 'model.zero_mean': True,\n",
       " 'model.custom_model': None,\n",
       " 'model.custom_action_dist': None,\n",
       " 'model.custom_preprocessor': None,\n",
       " 'model.lstm_use_prev_action_reward': -1,\n",
       " 'horizon': None,\n",
       " 'soft_horizon': False,\n",
       " 'no_done_at_end': False,\n",
       " 'env': None,\n",
       " 'observation_space': None,\n",
       " 'action_space': None,\n",
       " 'remote_worker_envs': False,\n",
       " 'remote_env_batch_wait_ms': 0,\n",
       " 'env_task_fn': None,\n",
       " 'render_env': False,\n",
       " 'record_env': False,\n",
       " 'clip_rewards': False,\n",
       " 'normalize_actions': True,\n",
       " 'clip_actions': False,\n",
       " 'preprocessor_pref': 'deepmind',\n",
       " 'log_level': 'WARN',\n",
       " 'callbacks': ray.rllib.agents.callbacks.DefaultCallbacks,\n",
       " 'ignore_worker_failures': False,\n",
       " 'log_sys_usage': True,\n",
       " 'fake_sampler': False,\n",
       " 'framework': 'tf',\n",
       " 'eager_tracing': False,\n",
       " 'eager_max_retraces': 20,\n",
       " 'explore': True,\n",
       " 'exploration_config.type': 'GaussianNoise',\n",
       " 'exploration_config.random_timesteps': 10000,\n",
       " 'exploration_config.stddev': 0.1,\n",
       " 'exploration_config.initial_scale': 1.0,\n",
       " 'exploration_config.final_scale': 1.0,\n",
       " 'exploration_config.scale_timesteps': 1,\n",
       " 'evaluation_interval': None,\n",
       " 'evaluation_num_episodes': 10,\n",
       " 'evaluation_parallel_to_training': False,\n",
       " 'in_evaluation': False,\n",
       " 'evaluation_config.explore': False,\n",
       " 'evaluation_num_workers': 0,\n",
       " 'custom_eval_function': None,\n",
       " 'sample_async': False,\n",
       " 'sample_collector': ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector,\n",
       " 'observation_filter': 'NoFilter',\n",
       " 'synchronize_filters': True,\n",
       " 'tf_session_args.intra_op_parallelism_threads': 2,\n",
       " 'tf_session_args.inter_op_parallelism_threads': 2,\n",
       " 'tf_session_args.gpu_options.allow_growth': True,\n",
       " 'tf_session_args.log_device_placement': False,\n",
       " 'tf_session_args.device_count.CPU': 1,\n",
       " 'tf_session_args.allow_soft_placement': True,\n",
       " 'local_tf_session_args.intra_op_parallelism_threads': 8,\n",
       " 'local_tf_session_args.inter_op_parallelism_threads': 8,\n",
       " 'compress_observations': False,\n",
       " 'collect_metrics_timeout': 180,\n",
       " 'metrics_smoothing_episodes': 100,\n",
       " 'min_iter_time_s': 1,\n",
       " 'timesteps_per_iteration': 1000,\n",
       " 'seed': None,\n",
       " 'num_gpus': 0,\n",
       " '_fake_gpus': False,\n",
       " 'num_cpus_per_worker': 1,\n",
       " 'num_gpus_per_worker': 0,\n",
       " 'num_cpus_for_driver': 1,\n",
       " 'placement_strategy': 'PACK',\n",
       " 'input': 'sampler',\n",
       " 'actions_in_input_normalized': False,\n",
       " 'input_evaluation': \"['is', 'wis']\",\n",
       " 'postprocess_inputs': False,\n",
       " 'shuffle_buffer_size': 0,\n",
       " 'output': None,\n",
       " 'output_compress_columns': \"['obs', 'new_obs']\",\n",
       " 'output_max_file_size': 67108864,\n",
       " 'multiagent.policy_map_capacity': 100,\n",
       " 'multiagent.policy_map_cache': None,\n",
       " 'multiagent.policy_mapping_fn': None,\n",
       " 'multiagent.policies_to_train': None,\n",
       " 'multiagent.observation_fn': None,\n",
       " 'multiagent.replay_mode': 'independent',\n",
       " 'multiagent.count_steps_by': 'env_steps',\n",
       " 'logger_config': None,\n",
       " '_tf_policy_handles_more_than_one_loss': False,\n",
       " '_disable_preprocessor_api': False,\n",
       " 'simple_optimizer': -1,\n",
       " 'monitor': -1,\n",
       " 'twin_q': True,\n",
       " 'policy_delay': 2,\n",
       " 'smooth_target_policy': True,\n",
       " 'target_noise': 0.2,\n",
       " 'target_noise_clip': 0.5,\n",
       " 'use_state_preprocessor': False,\n",
       " 'actor_hiddens': '[400, 300]',\n",
       " 'actor_hidden_activation': 'relu',\n",
       " 'critic_hiddens': '[400, 300]',\n",
       " 'critic_hidden_activation': 'relu',\n",
       " 'n_step': 1,\n",
       " 'buffer_size': 1000000,\n",
       " 'replay_buffer_config.type': 'LocalReplayBuffer',\n",
       " 'replay_buffer_config.capacity': 50000,\n",
       " 'store_buffer_in_checkpoints': False,\n",
       " 'prioritized_replay': False,\n",
       " 'prioritized_replay_alpha': 0.6,\n",
       " 'prioritized_replay_beta': 0.4,\n",
       " 'prioritized_replay_beta_annealing_timesteps': 20000,\n",
       " 'final_prioritized_replay_beta': 0.4,\n",
       " 'prioritized_replay_eps': 1e-06,\n",
       " 'training_intensity': None,\n",
       " 'critic_lr': 0.001,\n",
       " 'actor_lr': 0.001,\n",
       " 'target_network_update_freq': 0,\n",
       " 'tau': 0.005,\n",
       " 'use_huber': False,\n",
       " 'huber_threshold': 1.0,\n",
       " 'l2_reg': 0.0,\n",
       " 'grad_clip': None,\n",
       " 'learning_starts': 10000,\n",
       " 'worker_side_prioritization': False}"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "default_tde_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = []\n",
    "for (root, dirs, files) in os.walk(BASE_DIR):\n",
    "    if \"params.json\" not in files:\n",
    "        continue\n",
    "    \n",
    "    experimentName = root.replace(BASE_DIR, \"\")\n",
    "    with open(root+\"/params.json\", \"r\") as f:\n",
    "        params = json.load(f)\n",
    "    newDict = flatten_dict(params)\n",
    "    experimentName = experimentName.split(\"/\")\n",
    "    newDict[\"algo\"] = experimentName[0]\n",
    "    if len (experimentName) == 3:\n",
    "        newDict[\"experiment\"] = experimentName[1]\n",
    "        newDict[\"run\"] = experimentName[2]\n",
    "    else:\n",
    "        newDict[\"experiment\"] = experimentName[1] + \"/\" + experimentName[2]\n",
    "        newDict[\"run\"] = experimentName[3]\n",
    "    table.append(newDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "for exp in table:\n",
    "    if exp[\"algo\"]==\"TD3\":\n",
    "        for k,v in default_tde_config.items():\n",
    "            if k not in exp:\n",
    "                exp[k] = v\n",
    "    elif exp[\"algo\"]==\"PPO\":\n",
    "        for k,v in default_ppo_config.items():\n",
    "            if k not in exp:\n",
    "                exp[k] = v\n",
    "    elif exp[\"algo\"]==\"A3C\":\n",
    "        for k,v in default_a3c_config.items():\n",
    "            if k not in exp:\n",
    "                exp[k] = v\n",
    "    elif exp[\"algo\"]==\"SAC\":\n",
    "        for k,v in default_sac_config.items():\n",
    "            if k not in exp:\n",
    "                exp[k] = v\n",
    "    else:\n",
    "        continue\n",
    "        raise ValueError(\"No default config for algo: {}\".format(exp[\"algo\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(66, 200)"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(table)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df[\"algo\"]==\"TD3\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.fillna(\"-\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(47, 22)"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nunique = df.nunique()\n",
    "cols_to_drop = nunique[nunique == 1].index\n",
    "df = df.drop(cols_to_drop, axis=1)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = df.loc[:, [\"algo\", \"experiment\", \"run\"] + sorted([c for c in df.columns if c not in [\"algo\", \"experiment\", \"run\"]])]\n",
    "#df = df.sort_values([\"algo\", \"experiment\"])\n",
    "df = df.loc[:, [\"experiment\", \"run\"] + sorted([c for c in df.columns if c not in [\"algo\", \"experiment\", \"run\"]])]\n",
    "df = df.sort_values([\"experiment\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"ExperimentsTable_obst.csv\", sep=\";\", encoding=\"cp1251\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl_robots",
   "language": "python",
   "name": "rl_robots"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
