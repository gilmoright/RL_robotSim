В папке Configs 2 подпапки
- FollowerMinGrid - устаревшие конфиги для minigrid среды
- FollowerContinuous - в ней лежат актуальные конфиги для среды continuous-grid-arctic и устаревшие в папке FollowerContinuous/yml

В папке FollowerContinuous лежит несколько файлов в hocon (https://github.com/lightbend/config/blob/main/HOCON.md) формате. Среди них есть конфиги, которе настраивают общие части для экспериментов и конфиги самих экспериментов. Общие части конфигурируются в следующих файлах:- Environment.conf
- Architecture.conf
- Training.conf
- Exploration.conf

# Environment config
Environment.conf - конфиги среды. Здесь указываются настройки среды. Каждый конфиг должен иметь следующие ключи. 
Сначала идут настройки среды специально для ray:
- normalize_action - надо ли нормализовывать выходное пространство действий. В ray==1.9.2 с этим связаны определённые ошибки, поэтому рекомендуется ставить false
- env - название среды зарегистрированной через ray.tubne.register_env. Сейчас при импорте скрипта MyMisc регистрируется среда с названием "continuous-grid"
- env_config - настройки среды-обёртки. Здесь основные параметры: -- name имя gym среды, которую надо создать. 
Выбирается одна из тех, что регистрируются в continuous_grid_arctic/follow_the_leader_continuous_env.py -- wrappers - 
список используемых обёрток вокруг среды. Выбираются из continuous_grid_arctic/utils/wrappers.py -- base_env_config - 
здесь задаются параметры, которые принимает конструктор основной gym среды.

Рекомандации по именованию конфигов. каждый конфиг среды должен иметь префикс envconf_, чтоб не путаться с конфигами из 
других файлов. После этого следует версия среды, сейчас имеется следующая нумерация:

- v0 - первые пробные запуски, можно использовать в качестве базового конфига. Без препятствий.
- v1 - добавление 15 препятствий
- v2 - 15 препятствий, изменяющаяся скорость лидера и количество кадров
- v3 - 15 препятствий, изменяющаяся скорость лидера и количество кадров, дискретное пространство действий
- v4 - 35 препятствий, изменяющаяся скорость лидера и количество кадров, более длинные эпизоды и менее жётские условия на остановку симуляции в случае фейла
- v4v2 - 70 препятствий, изменяющаяся скорость лидера и количество кадров, более длинные эпизоды и менее жётские условия на остановку симуляции в случае фейла
- v5 - 35 препятствий, изменяющаяся скорость лидера и количество кадров, более длинные эпизоды и менее жётские условия на остановку симуляции в случае фейла, более узкая сейф зона
- v6 - 35 препятствий, изменяющаяся скорость лидера и количество кадров, более длинные эпизоды и менее жётские условия на остановку симуляции в случае фейла, дискретное пространство действий
- v7 - 35 препятствий, изменяющаяся скорость лидера и количество кадров, более длинные эпизоды и менее жётские условия на остановку симуляции в случае фейла, 3 точки маршрута вместо 1

Помимо настроек среды часто варьируются настройки признаков (follower_sensors). Для конфигов с вариациями признаков 
в название добавляется _feats_v№ и версия признаков. Какие номера соответствуют каким наборам точно не помню, может 
позже напишу. Основные, которые были использованы в 3Д среде это следующие:
- feats_v2v2 - только радар
- feats_v10v7 - радар + лидар
- feats_v12 - коридор и 7 усов-лазеров
- feats_v14v2 - коридор и 12 усов-лазеров до коридора и 30 до препятствий 


Другие используемые тэги:
- noNorm - в ray выключена нормализация экшенов. Рекомендуется именно так делать, то есть normalize_action = false
- \_MyNorm - попытка нормализовать экшены от 0 до 1 (или от -1 до 1, не помню) во враппере, вместо рэя. Разницы не заметил, поэтому перестал это делать.
- constSpeed - скорость ведомого зафиксирована, используется только 1 экшен - поворот
- obst - в среде используются препятствия
- dynLSpd - в среде используется изменение скорости лидера
- dynFPS - в среде используется разное количество кадров после принятия решения.
- noFeats - все сенсоры отключены. Такие конфиги нужны для того, чтобы настройку follower_sensors, это связано с 
реализацией hocon формата. Например, если в конфиге среды задан follower_sensors = {LeaderCorridor_laser = {...}}, 
от этого конфига наследуется новый конфиг и в нём задаётся follower_sensors = {LeaderTrackDetector_radar = {...}}, 
то на самом деле во втором случае будет и LeaderTrackDetector_radar и LeaderCorridor_laser. Чтобы этого избежать нужно 
между ними в дереве наследований иметь follower_sensors = null.

# Architecture config
Конфиги могут иметь параметры, упомянутые здесь https://docs.ray.io/en/latest/rllib/rllib-models.html.

Имена конфигов рекомендую начинаться с префиксов arch_. Также я добавляю постфикс _lstm если используется слой lstm и 
постфикс _ac если используется сетка для actor-critic алгоритма. Потому что параметр fcnet_hiddens не влияет на сетки 
актора и критика, им нужно задавать critic_hiddens и actor_hiddens.

# Training config
Гиперпараметры процесса обучения. лёрнинг рейт, нарезание эпизодов на фиксированные роллауты, батч сайз, минибатч сайз, 
сгд_минибатч сайз, и так далее. Комментарии к параметрам лучше искать в документации рея и лучше конкретно для используемой версии. 
Имена конфигов рекомендую начинаться с префиксов train_

# Exploration config
Гиперпараметры исследования в процессе сбора данных для обучения. Комментарии к параметрам лучше искать в документации 
рея и лучше конкретно для используемой версии. Имена конфигов рекомендую начинаться с префиксов excplore_

# Experiments config
Помимо выше описанных конфигов присутствуют конфигурации экспериментов. Они должны импортировать конфиги, т.е. 
в начале файла должно быть написано:
```
include "Environment.conf"
include "Exploration.conf"
include "Architecture.conf"
include "Training.conf"
```
Сейчас лучшие результаты достигаются с конфигами в файле PPO_obst.conf - эксперименты с алгоритмом PPO. 
В этом файле есть дефолтный конфиг ppo_default, в котором заданы только название среды, используемый алгоритм, путь 
к папке к сохранению экспериментов и некоторые другие параметры, которые я решил принять по умолчанию. Также стоит обратить 
внимание на колиечство воркеров (я использую 4, чтоб можно было запускать по 4 эксперимента за раз на одном узле), количество ГПУ 
(1 достаточно). А вот timesteps_per_iteration вроде ничего не делает полезного. Новые конфиги рекомендую создавать следующим образом:

```
ppo_env7feats10v7_train5v2 = ${ppo_default}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous/env7/PPO/feats10v7_train
    stop {
        training_iteration = 800
    }
    config = ${envconf_v7_feats_v10v7}  ${train_v5v2_sqd}
}
```

Этот конфиг берёт параметры, из ppo_default, меняет путь к сохранению модели, количество итераций, а также берёт 
настройки среды из файла Environment.conf из конфигурации envconf_v7_feats_v10v7 и настройки обучения из файла Training.conf конфига train_v5v2_sqd.

Папку для сохранения рекомендую делать такую: папка_репозитория/results/FollowerContinuous/основная_версия_среды/алгоритм_обучения/
фиксированная_часть_конфига+варьируемая_часть_конфига/. Например в /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous/env7/PPO/feats10v7_train я зафиксировал признаки feats10v7, но варьировал настройки обучения.

Имеющиеся файлы с экспериментами:
- A2C_obst.conf - алгоритм актор критик 2 - можно забыть
- A3C_noObst_constSpeed.conf - алгоритм актор критик 3, с постоянной скоростью и только одним действием - поворотом
- A3C_obst.conf - алгоритм актор критик 3 с препятствиями
- A3C_obstDiscr.conf - алгоритм актор критик 3 с препятствиями и дискретными действиями. хотел заставить его работать 
в нашей среде, чтоб сравнить с алгоритмом Дёмина
- allDefault_obst.conf - эксперименты с разными алгоритмами, но с дефолтными настройками для всех.
- PPO_noObst.conf - PPO в среде без препятствий
- PPO_noObst_constSpeed.conf - PPO в среде без препятствий с постоянной скоростью
- PPO_obst.conf - PPO в среде с препятствиями
- PPO_dyn_obst.conf - PPO в среде со статическими и динамическими препятствиями
- PPO_dyn_obst_2.conf - PPO в среде со статическими и динамическими препятствиями (новый)
- SAC_noObst_constSpeed.conf - SAC в среде без препятствий с постоянной скоростью
- TD3_noObst.conf - TD3 в среде без препятствий
- TD3_noObst_constSpeed.conf - TD3 в среде без препятствий с постоянной скоростью
- TD3_obst.conf - TD3 в среде с препятствиями

