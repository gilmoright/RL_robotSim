include "Environment.conf"
include "Exploration.conf"
include "Architecture.conf"
include "Training.conf"

ppo_default {
    env = continuous-grid
    run = PPO
    local_dir = /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous/obst/PPO/
    checkpoint_freq = 10
    stop {
        training_iteration = 400
    }
    config {
        num_gpus = 1
        timesteps_per_iteration = 1000
        num_workers = 4
        log_level = WARNING
        framework = torch
    }    
}

ppo_v0 = ${ppo_default}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous/env4/PPO/
    config = ${envconf_v2_obst_noNorm_dynLSpd_dynFPS}
}

ppo_arch3_feats9 = ${ppo_default}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous/env4/PPO/
    config = ${envconf_v2_feats_v9} ${arch_v3}
}

############################
### features_experiments ###
############################
ppo_featsv1 = ${ppo_default}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous/env4/PPO/feats
    config = ${envconf_v2_feats_v1}
}
ppo_featsv2 = ${ppo_default}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous/env4/PPO/feats
    config = ${envconf_v2_feats_v2}
}
ppo_featsv3 = ${ppo_default}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous/env4/PPO/feats
    config = ${envconf_v2_feats_v3}
}
ppo_featsv4 = ${ppo_default}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous/env4/PPO/feats
    config = ${envconf_v2_feats_v4}
}
ppo_featsv5 = ${ppo_default}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous/env4/PPO/feats
    config = ${envconf_v2_feats_v5}
}
ppo_featsv6 = ${ppo_default}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous/env4/PPO/feats
    config = ${envconf_v2_feats_v6}
}
ppo_featsv7 = ${ppo_default}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous/env4/PPO/feats
    config = ${envconf_v2_feats_v7}
}
ppo_featsv8 = ${ppo_default}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous/env4/PPO/feats
    config = ${envconf_v2_feats_v8}
}
ppo_featsv9 = ${ppo_default}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous/env4/PPO/feats
    config = ${envconf_v2_feats_v9}
}

################################
### architecture experiments ###
################################
ppo_archv3 = ${ppo_default}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous/env4/PPO/arch
    config = ${envconf_v2_obst_noNorm_dynLSpd_dynFPS} ${arch_v3}
}
ppo_archv3lstm = ${ppo_default}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous/env4/PPO/arch
    config = ${envconf_v2_obst_noNorm_dynLSpd_dynFPS} ${arch_v3_lstm}
}
ppo_archv3lstm2 = ${ppo_default}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous/env4/PPO/arch
    config = ${envconf_v2_obst_noNorm_dynLSpd_dynFPS} ${arch_v3_lstm2}
}
ppo_archv3lstm3 = ${ppo_default}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous/env4/PPO/arch
    config = ${envconf_v2_obst_noNorm_dynLSpd_dynFPS} ${arch_v3_lstm3}
}
ppo_archv4 = ${ppo_default}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous/env4/PPO/arch
    config = ${envconf_v2_obst_noNorm_dynLSpd_dynFPS} ${arch_v4}
}
ppo_archv4lstm = ${ppo_default}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous/env4/PPO/arch
    config = ${envconf_v2_obst_noNorm_dynLSpd_dynFPS} ${arch_v4_lstm}
}
ppo_archv5 = ${ppo_default}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous/env4/PPO/arch
    config = ${envconf_v2_obst_noNorm_dynLSpd_dynFPS} ${arch_v5}
}
ppo_archv5lstm = ${ppo_default}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous/env4/PPO/arch
    config = ${envconf_v2_obst_noNorm_dynLSpd_dynFPS} ${arch_v5_lstm}
}


###############################
### exploration experiments ###
###############################
ppo_expl_gaus = ${ppo_default}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous/env4/PPO/explore
    config = ${envconf_v2_obst_noNorm_dynLSpd_dynFPS} ${expl_Gaussdefault}
}
ppo_expl_oun = ${ppo_default}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous/env4/PPO/explore
    config = ${envconf_v2_obst_noNorm_dynLSpd_dynFPS} ${expl_OUNdefault}
}
ppo_explv1 = ${ppo_default}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous/env4/PPO/explore
    config = ${envconf_v2_obst_noNorm_dynLSpd_dynFPS} ${expl_v1}
}
ppo_explv4 = ${ppo_default}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous/env4/PPO/explore
    config = ${envconf_v2_obst_noNorm_dynLSpd_dynFPS} ${expl_v4}
}

###############################
###          ENV 4          ###
# env4 == obst_dynLSpd_dynFPS #
###############################


ppo_env4 = ${ppo_default}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous/env4/PPO/feats
    stop {
        training_iteration = 800
    }
    config = ${envconf_v4}
}

ppo_env4_train5v2 = ${ppo_default}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous/env4/PPO/train
    stop {
        training_iteration = 800
    }
    config = ${envconf_v4} ${train_v5v2_sqd}
}

ppo_env4_featsv2 = ${ppo_default}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous/env4/PPO/feats
    stop {
        training_iteration = 800
    }
    config = ${envconf_v4_feats_v2}
}
ppo_env4feats2v2_train5v2 = ${ppo_default}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous/env4/PPO/feats2v2_train
    stop {
        training_iteration = 800
    }
    config = ${envconf_v4_feats_v2v2} ${train_v5v2_sqd}
}
ppo_env4_featsv9v2 = ${ppo_default}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous/env4/PPO/feats
    stop {
        training_iteration = 800
    }
    config = ${envconf_v4_feats_v9v2}
}

ppo_env4feats9v3_train5v2 = ${ppo_default}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous/env4/PPO/feats
    stop {
        training_iteration = 800
    }
    config = ${envconf_v4_feats_v9v3} ${train_v5v2_sqd}
}
ppo_env4_featsv10 = ${ppo_default}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous/env4/PPO/feats
    stop {
        training_iteration = 800
    }
    config = ${envconf_v4_feats_v10}
}
# бывший v11
ppo_env4_feats10v2 = ${ppo_default}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous/env4/PPO/feats
    stop {
        training_iteration = 800
    }
    config = ${envconf_v4_feats_v10v2}
}
ppo_env4_feats10v3 = ${ppo_default}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous/env4/PPO/feats
    stop {
        training_iteration = 800
    }
    config = ${envconf_v4_feats_v10v3} 
}
ppo_env4_feats10v4 = ${ppo_default}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous/env4/PPO/feats
    stop {
        training_iteration = 800
    }
    config = ${envconf_v4_feats_v10v4} 
}
ppo_env4_feats10v5 = ${ppo_default}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous/env4/PPO/feats
    stop {
        training_iteration = 800
    }
    config = ${envconf_v4_feats_v10v5} 
}
ppo_env4_feats10v6 = ${ppo_default}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous/env4/PPO/feats
    stop {
        training_iteration = 800
    }
    config = ${envconf_v4_feats_v10v6} 
}
ppo_env4_feats10v7 = ${ppo_default}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous/env4/PPO/feats
    stop {
        training_iteration = 800
    }
    config = ${envconf_v4_feats_v10v7} 
}
ppo_env4_feats10v8 = ${ppo_default}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous/env4/PPO/feats
    stop {
        training_iteration = 800
    }
    config = ${envconf_v4_feats_v10v8} 
}
ppo_env4_feats10v9 = ${ppo_default}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous/env4/PPO/feats
    stop {
        training_iteration = 800
    }
    config = ${envconf_v4_feats_v10v9} 
}
ppo_env4_feats10v10 = ${ppo_default}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous/env4/PPO/feats
    stop {
        training_iteration = 800
    }
    config = ${envconf_v4_feats_v10v10} 
}
ppo_env4_feats10v11 = ${ppo_default}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous/env4/PPO/feats
    stop {
        training_iteration = 800
    }
    config = ${envconf_v4_feats_v10v11} 
}
ppo_env4_feats10v12 = ${ppo_default}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous/env4/PPO/feats
    stop {
        training_iteration = 800
    }
    config = ${envconf_v4_feats_v10v12} 
}
ppo_env4_feats10v13 = ${ppo_default}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous/env4/PPO/feats
    stop {
        training_iteration = 800
    }
    config = ${envconf_v4_feats_v10v13} 
}
ppo_env4_feats7 = ${ppo_default}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous/env4/PPO/feats
    stop {
        training_iteration = 800
    }
    config = ${envconf_v4_feats_v7} 
}
ppo_env4_feats11 = ${ppo_default}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous/env4/PPO/feats
    stop {
        training_iteration = 800
    }
    config = ${envconf_v4_feats_v11} 
}

ppo_env4_feats12 = ${ppo_default}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous/env4/PPO/feats
    stop {
        training_iteration = 800
    }
    config = ${envconf_v4_feats_v11}
}


ppo_env5 = ${ppo_default}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous/env4/PPO/feats
    stop {
        training_iteration = 800
    }
    config = ${envconf_v5}
}
ppo_env5v2 = ${ppo_default}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous/env4/PPO/feats
    stop {
        training_iteration = 800
    }
    config = ${envconf_v5v2}
}


################################
###    Env v4, feats 10v2    ###
### Architecture experiments ###
################################
ppo_env4feats10v2_arch5 = ${ppo_default}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous/env4/PPO/env4feats10v2_arch
    stop {
        training_iteration = 800
    }
    config = ${envconf_v4_feats_v10v2}  ${arch_v5}
}

################################
###    Env v4, feats 10v7    ###
### Architecture experiments ###
################################
ppo_env4feats10v7_arch5 = ${ppo_default}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous/env4/PPO/env4feats10v7_arch
    stop {
        training_iteration = 800
    }
    config = ${envconf_v4_feats_v10v7}  ${arch_v5}
}

ppo_env4feats10v7_arch6 = ${ppo_default}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous/env4/PPO/env4feats10v7_arch
    stop {
        training_iteration = 800
    }
    config = ${envconf_v4_feats_v10v7}  ${arch_v6}
}
################################
###    Env v4, feats 10v7    ###
###   Training experiments   ###
################################
ppo_env4feats10v7_train5v2 = ${ppo_default}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous/env4/PPO/env4feats10v7_train
    stop {
        training_iteration = 800
    }
    config = ${envconf_v4_feats_v10v7}  ${train_v5v2_sqd}
}
ppo_env4feats10v7_train5v3 = ${ppo_default}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous/env4/PPO/env4feats10v7_train
    stop {
        training_iteration = 800
    }
    config = ${envconf_v4_feats_v10v7}  ${train_v5v3_sqd}
}
ppo_env4feats10v7_train5v4 = ${ppo_default}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous/env4/PPO/env4feats10v7_train
    stop {
        training_iteration = 800
    }
    config = ${envconf_v4_feats_v10v7}  ${train_v5v4_sqd}
}
ppo_env4feats10v7_train5v5 = ${ppo_default}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous/env4/PPO/env4feats10v7_train
    stop {
        training_iteration = 800
    }
    config = ${envconf_v4_feats_v10v7}  ${train_v5v5_sqd} 
}
################################
###    Env v4, feats 12    ###
###   Training experiments   ###
################################
ppo_env4feats12_train5v2 = ${ppo_default}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous/env4/PPO/env4feats12_train
    stop {
        training_iteration = 800
    }
    config = ${envconf_v4_feats_v12}  ${train_v5v2_sqd} 
}

ppo_env4feats12_train5v6 = ${ppo_default}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous/env4/PPO/env4feats12_train
    stop {
        training_iteration = 800
    }
    config = ${envconf_v4_feats_v12}  ${train_v5v6_sqd} 
}

################################
###     Env v4v2             ###
###    Feature experiments   ###
################################
ppo_env4v2 = ${ppo_default}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous/env4v2/PPO/
    stop {
        training_iteration = 800
    }
    config = ${envconf_v4v2}
}

ppo_env4v2feats10v7 = ${ppo_default}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous/env4v2/PPO/env4v2feats
    stop {
        training_iteration = 800
    }
    config = ${envconf_v4v2_feats_v10v7}
}
ppo_env4v2feats2v2_train5v2 = ${ppo_default}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous/env4v2/PPO/feats2v2_train
    stop {
        training_iteration = 800
    }
    config = ${envconf_v4v2_feats_v2v2} ${train_v5v2_sqd}
}

ppo_env4v2feats9v3_train5v2 = ${ppo_default}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous/env4v2/PPO/feats2v2_train
    stop {
        training_iteration = 800
    }
    config = ${envconf_v4v2_feats_v9v3} ${train_v5v2_sqd}
}

################################
###    Env v4v2, feats 10v7  ###
###   Training experiments   ###
################################
ppo_env4v2_train5v2 = ${ppo_default}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous/env4v2/PPO/train
    stop {
        training_iteration = 800
    }
    config = ${envconf_v4v2}  ${train_v5v2_sqd}
}
ppo_env4v2feats10v7_train5v2 = ${ppo_default}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous/env4v2/PPO/env4v2feats10v7_train
    stop {
        training_iteration = 800
    }
    config = ${envconf_v4v2_feats_v10v7}  ${train_v5v2_sqd}
}

################################
###    Env v7               ###
###   Feature experiments   ###
################################

ppo_env7 = ${ppo_default}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous/env7/PPO
    stop {
        training_iteration = 800
    }
    config = ${envconf_v7}
}


ppo_env7_feats10v7 = ${ppo_default}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous/env7/PPO/feats
    stop {
        training_iteration = 800
    }
    config = ${envconf_v7_feats_v10v7}
}


ppo_env7feats2v2_train5v2 = ${ppo_default}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous/env7/PPO/feats2v2_train
    stop {
        training_iteration = 800
    }
    config = ${envconf_v7_feats_v2v2} ${train_v5v2_sqd}
}

ppo_env7feats9v3_train5v2 = ${ppo_default}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous/env7/PPO/feats2v2_train
    stop {
        training_iteration = 800
    }
    config = ${envconf_v7_feats_v9v3} ${train_v5v2_sqd}
}
################################
###    Env v7, feats 10v7    ###
###   Training experiments   ###
################################
ppo_env7_train5v2 = ${ppo_default}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous/env7/PPO/train
    stop {
        training_iteration = 800
    }
    config = ${envconf_v7}  ${train_v5v2_sqd}
}

ppo_env7feats10v7_train5v2 = ${ppo_default}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous/env7/PPO/feats10v7_train
    stop {
        training_iteration = 800
    }
    config = ${envconf_v7_feats_v10v7}  ${train_v5v2_sqd}
}

################################
###    Env v8, feats 12      ###
###   Training experiments   ###
################################

ppo_env8feats_v12_train5v7 = ${ppo_default}  {
    local_dir: /s/ls4/users/slava1195/rl_rob/RL_robotSim/results/FollowerContinuous/env8/PPO/feats_v12_train
#     local_dir: /home/sheins/rl-test/RL_robotSim/results/FollowerContinuous/env8/PPO/feats_v12_train

    stop {
        training_iteration = 400
    }
    config = ${envconf_v8_feats_v12}  ${train_v5v7_sqd}
}

ppo_env8feats_v12_train5v2 = ${ppo_default}  {
    local_dir: /s/ls4/users/slava1195/rl_rob/RL_robotSim/results/FollowerContinuous/env8/PPO/feats_v12_train
    stop {
        training_iteration = 800
    }
    config = ${envconf_v8_feats_v12}  ${train_v5v2_sqd}
}

ppo_env8v2feats_v12_train5v7 = ${ppo_default}  {
    local_dir: /s/ls4/users/slava1195/rl_rob/RL_robotSim/results/FollowerContinuous/env8v2/PPO/feats_v12_train
#     local_dir: /home/sheins/rl-test/RL_robotSim/results/FollowerContinuous/env8/PPO/feats_v12_train

    stop {
        training_iteration = 400
    }
    config = ${envconf_v8v2_feats_v12}  ${train_v5v7_sqd}
}
