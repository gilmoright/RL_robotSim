include "Environment_2.conf"
include "Exploration.conf"
include "Architecture.conf"
include "Architecture_2.conf"
include "Training.conf"

ppo_default {
    env = continuous-grid
    run = PPO
    local_dir = /s/ls4/users/slava1195/rl_rob/RL_robotSim/results/FollowerContinuous/dyn_obst/PPO/
    checkpoint_freq = 10
    stop {
        training_iteration = 400
    }
    config {
        num_gpus = 1
        timesteps_per_iteration = 1000
        num_workers = 4
        log_level = WARNING
        framework = torch
    }    
}



ppo_dv1 = ${ppo_default}  {
    checkpoint_freq = 5

    stop {
        training_iteration = 400
    }
    config {
        num_gpus = 1
        timesteps_per_iteration = 1000
        num_workers = 4
        log_level = WARNING
        framework = torch
    }
}




######################################

ppo_e28_b1_f14_m_def = ${ppo_dv1}  {
    local_dir: /s/ls4/users/slava1195/rl_rob/RL_robotSim/results/FollowerContinuous_2/env28/PPO/default_model/feats_v14
    stop {
        training_iteration = 250
    }
    config = ${envconf_v28_b1_feats_v14} ${train_v5v2_sqd} ${default_keras_model}
}

######################################

ppo_e28_b1_f14_prev5_m_def = ${ppo_dv1}  {
    local_dir: /s/ls4/users/slava1195/rl_rob/RL_robotSim/results/FollowerContinuous_2/env28/PPO/default_model/feats_v14
    stop {
        training_iteration = 250
    }
    config = ${envconf_v28_b1_feats_v14_prev5} ${train_v5v2_sqd} ${default_keras_model_prev}
}

ppo_e28_b1_f14_prev5_m_lstm = ${ppo_dv1}  {
    local_dir: /s/ls4/users/slava1195/rl_rob/RL_robotSim/results/FollowerContinuous_2/env28/PPO/default_model/feats_v14
    stop {
        training_iteration = 250
    }
    config = ${envconf_v28_b1_feats_v14_prev5} ${train_v5v2_sqd} ${lstm_model}
}


######################################
### test experiments for prev sensors
######################################

ppo_e28_b1_f14v2_prev5_m_def_v1 = ${ppo_dv1}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous_Prev/env28/PPO/default_model/feats_v14v2
    stop {
        training_iteration = 250
    }
    config = ${envconf_v28_b1_feats_v14v2_prev5} ${train_v5v2_sqd} ${def_m_prev}
}

ppo_e28_b2_f14v2_prev5_m_def_v1 = ${ppo_dv1}  {
    local_dir: /s/ls4/users/slava1195/rl_rob/RL_robotSim/results/FollowerContinuous_Prev/env28/PPO/default_model/feats_v14v2
    stop {
        training_iteration = 250
    }
    config = ${envconf_v28_b2_feats_v14v2_prev5} ${train_v5v2_sqd} ${def_m_prev}
}

##########
#  LSTM  #
##########

ppo_e28_b1_f14v2_prev5_m_lstm_v1 = ${ppo_dv1}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous_Prev/env28/PPO/default_model/feats_v14v2
    stop {
        training_iteration = 250
    }
    config = ${envconf_v28_b1_feats_v14v2_prev5} ${train_v5v2_sqd} ${def_lstm_m_prev}
}

#################
#  Transformer  #
#################

ppo_e28_b1_f14v2_prev5_m_trans_v1 = ${ppo_dv1}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous_Prev/env28/PPO/default_model/feats_v14v2
    stop {
        training_iteration = 250
    }
    config = ${envconf_v28_b1_feats_v14v2_prev5} ${train_v5v2_sqd} ${my_transformer_model}
}

ppo_e28_b1_f14v2_prev5_m_trans_v4 = ${ppo_dv1}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous_Prev/env28/PPO/default_model/feats_v14v2
    stop {
        training_iteration = 250
    }
    config = ${envconf_v28_b1_feats_v14v2_prev5} ${train_v5v2_sqd} ${my_transformer_model_v4}
}
ppo_e28_b1_f14v2_prev5_m_trans_v4v2 = ${ppo_dv1}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous_Prev/env28/PPO/default_model/feats_v14v2
    stop {
        training_iteration = 250
    }
    config = ${envconf_v28_b1_feats_v14v2_prev5} ${train_v5v2_sqd} ${my_transformer_model_v4v2}
}
ppo_e28_b1_f14v2_prev5_m_trans_v4v3 = ${ppo_dv1}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous_Prev/env28/PPO/default_model/feats_v14v2
    stop {
        training_iteration = 250
    }
    config = ${envconf_v28_b1_feats_v14v2_prev5} ${train_v5v2_sqd} ${my_transformer_model_v4v3}
}
ppo_e28_b1_f14v2_prev5_m_trans_v5 = ${ppo_dv1}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous_Prev/env28/PPO/default_model/feats_v14v2
    stop {
        training_iteration = 250
    }
    config = ${envconf_v28_b1_feats_v14v2_prev5} ${train_v5v2_sqd} ${my_transformer_model_v5}
}


