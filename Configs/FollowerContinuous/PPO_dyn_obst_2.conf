include "Environment_2.conf"
include "Exploration.conf"
include "Architecture.conf"
include "Architecture_2.conf"
include "Training.conf"

ppo_default {
    env = continuous-grid
    run = PPO
    local_dir = /s/ls4/users/slava1195/rl_rob/RL_robotSim/results/FollowerContinuous/dyn_obst/PPO/
    checkpoint_freq = 10
    stop {
        training_iteration = 400
    }
    config {
        num_gpus = 1
        timesteps_per_iteration = 1000
        num_workers = 4
        log_level = WARNING
        framework = torch
    }    
}



ppo_dv1 = ${ppo_default}  {
    checkpoint_freq = 5

    stop {
        training_iteration = 400
    }
    config {
        num_gpus = 1
        timesteps_per_iteration = 1000
        num_workers = 4
        log_level = WARNING
        framework = torch
    }
}




######################################

ppo_e28_b1_f14_m_def = ${ppo_dv1}  {
    local_dir: /s/ls4/users/slava1195/rl_rob/RL_robotSim/results/FollowerContinuous_2/env28/PPO/default_model/feats_v14
    stop {
        training_iteration = 250
    }
    config = ${envconf_v28_b1_feats_v14} ${train_v5v2_sqd} ${default_keras_model}
}

######################################

ppo_e28_b1_f14_prev5_m_def = ${ppo_dv1}  {
    local_dir: /s/ls4/users/slava1195/rl_rob/RL_robotSim/results/FollowerContinuous_2/env28/PPO/default_model/feats_v14
    stop {
        training_iteration = 250
    }
    config = ${envconf_v28_b1_feats_v14_prev5} ${train_v5v2_sqd} ${default_keras_model_prev}
}

ppo_e28_b1_f14_prev5_m_lstm = ${ppo_dv1}  {
    local_dir: /s/ls4/users/slava1195/rl_rob/RL_robotSim/results/FollowerContinuous_2/env28/PPO/default_model/feats_v14
    stop {
        training_iteration = 250
    }
    config = ${envconf_v28_b1_feats_v14_prev5} ${train_v5v2_sqd} ${lstm_model}
}


######################################
### test experiments for prev sensors
######################################

ppo_e28_b1_f14v2_prev5_m_def_v1 = ${ppo_dv1}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous_Prev/env28/PPO/default_model/feats_v14v2
    stop {
        training_iteration = 250
    }
    config = ${envconf_v28_b1_feats_v14v2_prev5} ${train_v5v2_sqd} ${def_m_prev}
}

ppo_e28_b2_f14v2_prev5_m_def_v1 = ${ppo_dv1}  {
    local_dir: /s/ls4/users/slava1195/rl_rob/RL_robotSim/results/FollowerContinuous_Prev/env28/PPO/default_model/feats_v14v2
    stop {
        training_iteration = 250
    }
    config = ${envconf_v28_b2_feats_v14v2_prev5} ${train_v5v2_sqd} ${def_m_prev}
}
ppo_e28_b1_f14v2_prev5_m_defv1_train_v5v16 = ${ppo_dv1}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous_Prev/env28/PPO/default_model/feats_v14v2/train
    stop {
        training_iteration = 250
    }
    config = ${envconf_v28_b1_feats_v14v2_prev5} ${train_v5v16_ppo} ${def_m_prev}
}

##########
#  LSTM  #
##########

ppo_e28_b1_f14v2_prev5_m_lstm_v1 = ${ppo_dv1}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous_Prev/env28/PPO/default_model/feats_v14v2
    stop {
        training_iteration = 250
    }
    config = ${envconf_v28_b1_feats_v14v2_prev5} ${train_v5v2_sqd} ${def_lstm_m_prev}
}

#################
#  Transformer  #
#################

ppo_e28_b1_f14v2_prev5_m_trans_v1 = ${ppo_dv1}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous_Prev/env28/PPO/default_model/feats_v14v2
    stop {
        training_iteration = 250
    }
    config = ${envconf_v28_b1_feats_v14v2_prev5} ${train_v5v2_sqd} ${my_transformer_model}
}

ppo_e28_b1_f14v2_prev5_m_trans_v4 = ${ppo_dv1}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous_Prev/env28/PPO/default_model/feats_v14v2
    stop {
        training_iteration = 250
    }
    config = ${envconf_v28_b1_feats_v14v2_prev5} ${train_v5v2_sqd} ${my_transformer_model_v4}
}
ppo_e28_b1_f14v2_prev5_m_trans_v4v2 = ${ppo_dv1}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous_Prev/env28/PPO/default_model/feats_v14v2
    stop {
        training_iteration = 250
    }
    config = ${envconf_v28_b1_feats_v14v2_prev5} ${train_v5v2_sqd} ${my_transformer_model_v4v2}
}
ppo_e28_b1_f14v2_prev5_m_trans_v4v3 = ${ppo_dv1}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous_Prev/env28/PPO/default_model/feats_v14v2
    stop {
        training_iteration = 250
    }
    config = ${envconf_v28_b1_feats_v14v2_prev5} ${train_v5v2_sqd} ${my_transformer_model_v4v3}
}
ppo_e28_b1_f14v2_prev5_m_trans_v4v4 = ${ppo_dv1}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous_Prev/env28/PPO/default_model/feats_v14v2
    stop {
        training_iteration = 250
    }
    config = ${envconf_v28_b1_feats_v14v2_prev5} ${train_v5v2_sqd} ${my_transformer_model_v4v4}
}

ppo_e28_b1_f14v2_prev5_m_raytrans = ${ppo_dv1}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous_Prev/env28/PPO/raytrans/feats_v14v2
    stop {
        training_iteration = 250
    }
    config = ${envconf_v28_b1_feats_v14v2_prev5} ${train_v5v2_sqd} ${model_raytrans_v1}
}


ppo_e28_b1_f14v2_prev5_m_transv4v2_train_v5v6sqd = ${ppo_dv1}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous_Prev/env28/PPO/trans/trans_v4v2/train/
    stop {
        training_iteration = 250
    }
    config = ${envconf_v28_b1_feats_v14v2_prev5} ${train_v5v6_sqd} ${my_transformer_model_v4v2}
}
ppo_e28_b1_f14v2_prev5_m_transv4v2_train_v5v10ppo = ${ppo_dv1}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous_Prev/env28/PPO/trans/trans_v4v2/train/
    stop {
        training_iteration = 250
    }
    config = ${envconf_v28_b1_feats_v14v2_prev5} ${train_v5v10_ppo} ${my_transformer_model_v4v2}
}
ppo_e28_b1_f14v2_prev5_m_transv4v2_train_v5v11sqd = ${ppo_dv1}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous_Prev/env28/PPO/trans/trans_v4v2/train/
    stop {
        training_iteration = 250
    }
    config = ${envconf_v28_b1_feats_v14v2_prev5} ${train_v5v11_sqd} ${my_transformer_model_v4v2} 
}
ppo_e28_b1_f14v2_prev5_m_transv4v2_train_v5v12ppo = ${ppo_dv1}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous_Prev/env28/PPO/trans/trans_v4v2/train/
    stop {
        training_iteration = 250
    }
    config = ${envconf_v28_b1_feats_v14v2_prev5} ${train_v5v12_ppo} ${my_transformer_model_v4v2} 
}

ppo_e28_b1_f14v2_prev5_m_transv4v2_train_v5v13ppo = ${ppo_dv1}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous_Prev/env28/PPO/trans/trans_v4v2/train/
    stop {
        training_iteration = 250
    }
    config = ${envconf_v28_b1_feats_v14v2_prev5} ${train_v5v13_ppo} ${my_transformer_model_v4v2} 
}

ppo_e28_b1_f14v2_prev5_m_transv4v2_train_v5v14ppo = ${ppo_dv1}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous_Prev/env28/PPO/trans/trans_v4v2/train/
    stop {
        training_iteration = 250
    }
    config = ${envconf_v28_b1_feats_v14v2_prev5} ${train_v5v14_ppo} ${my_transformer_model_v4v2} 
}

ppo_e28_b1_f14v2_prev5_m_transv4v2_train_v5v15ppo = ${ppo_dv1}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous_Prev/env28/PPO/trans/trans_v4v2/train/
    stop {
        training_iteration = 250
    }
    config = ${envconf_v28_b1_feats_v14v2_prev5} ${train_v5v15_ppo} ${my_transformer_model_v4v2} 
}

ppo_e28_b1_f14v2_prev5_m_transv4v2_train_v5v16ppo = ${ppo_dv1}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous_Prev/env28/PPO/trans/trans_v4v2/train/
    stop {
        training_iteration = 250
    }
    config = ${envconf_v28_b1_feats_v14v2_prev5} ${train_v5v16_ppo} ${my_transformer_model_v4v2} 
}

ppo_e28_b1_f14v2_prev5_m_transv4v2_train_v5v17ppo = ${ppo_dv1}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous_Prev/env28/PPO/trans/trans_v4v2/train/
    stop {
        training_iteration = 250
    }
    config = ${envconf_v28_b1_feats_v14v2_prev5} ${train_v5v17_ppo} ${my_transformer_model_v4v2} 
}
ppo_e28_b1_f14v2_prev5_m_transv4v5_train_v5v16ppo = ${ppo_dv1}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous_Prev/env28/PPO/trans/
    stop {
        training_iteration = 250
    }
    config = ${envconf_v28_b1_feats_v14v2_prev5} ${train_v5v16_ppo} ${my_transformer_model_v4v5} 
}


#####################
#  Ray Transformer  #
#####################


ppo_e28_b1_f14v2_prev5_m_raytrans = ${ppo_dv1}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous_Prev/env28/PPO/raytrans/feats_v14v2
    stop {
        training_iteration = 250
    }
    config = ${envconf_v28_b1_feats_v14v2_prev1} ${train_v5v2_sqd} ${model_raytrans_v1}
}

ppo_e28_b1_f14v2_prev5_m_raytrans_train_v5v16ppo = ${ppo_dv1}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous_Prev/env28/PPO/featsv14v2_raytrans/train
    stop {
        training_iteration = 250
    }
    config = ${envconf_v28_b1_feats_v14v2_prev1} ${train_v5v16_ppo} ${model_raytrans_v1} 
}


####################
#    test modify   #
####################

ppo_e28_b2_f14v2_prev5_m_def_v1_test_mody = ${ppo_dv1}  {
    local_dir: /s/ls4/users/slava1195/rl_rob/RL_robotSim/results/FollowerContinuous_Prev/env28/PPO/default_model/feats_v14v2
    stop {
        training_iteration = 300
    }
    config = ${envconf_v28_b2_feats_v14v2_prev5_test_mody} ${train_v5v7_sqd} ${def_m_prev_v2}
}

############
# BI LSTM  #
############

ppo_e28_b2_f14v2_prev5_m_bi_lstm_v2_low = ${ppo_dv1}  {
    local_dir: /s/ls4/users/slava1195/rl_rob/RL_robotSim/results/FollowerContinuous_Prev/env28/PPO/default_model/feats_v14v2
    stop {
        training_iteration = 250
    }
    config = ${envconf_v28_b2_feats_v14v2_prev5_test_mody_low} ${train_v5v7_sqd} ${bi_lstm_v2_m_prev}
}

ppo_e28_b2_f14v2_prev5_m_bi_lstm_v2 = ${ppo_dv1}  {
    local_dir: /s/ls4/users/slava1195/rl_rob/RL_robotSim/results/FollowerContinuous_Prev/env28/PPO/default_model/feats_v14v2
    stop {
        training_iteration = 250
    }
    config = ${envconf_v28_b2_feats_v14v2_prev5_test_mody} ${train_v5v7_sqd} ${bi_lstm_v2_m_prev}
}



##################
# LSTM prev 20   #
##################

ppo_e28_b2_f14v2_prev20_m_lstm_v1 = ${ppo_dv1}  {
    local_dir: /s/ls4/users/slava1195/rl_rob/RL_robotSim/results/FollowerContinuous_Prev/env28/PPO/default_model/feats_v14v2
    stop {
        training_iteration = 250
    }
    config = ${envconf_v28_b2_feats_v14v2_prev20_test_mody} ${train_v5v7_sqd} ${def_lstm_m_prev}
}




#######################################################################################
### под статью 1 блок (12 лучей)
#######################################################################################


ppo_e29_stat_f12v1 = ${ppo_dv1}  {
    local_dir: /s/ls4/users/slava1195/rl_rob/RL_robotSim/results/FollowerContinuous_paper/env29/PPO/default_model/feats_v12v2/no_bear
    stop {
        training_iteration = 250
    }
    config = ${old_envconf_v29_feats_v12v1_stat} ${train_v5v7_sqd}
}

ppo_e29_b1_f12v1_ar = ${ppo_dv1}  {
    local_dir: /s/ls4/users/slava1195/rl_rob/RL_robotSim/results/FollowerContinuous_paper/env29/PPO/default_model/feats_v12v2/bear1
    stop {
        training_iteration = 250
    }
    config = ${old_envconf_v29_feats_v12v1_bear1_around} ${train_v5v7_sqd}
}

ppo_e29_b1_f12v1_mv4 = ${ppo_dv1}  {
    local_dir: /s/ls4/users/slava1195/rl_rob/RL_robotSim/results/FollowerContinuous_paper/env29/PPO/default_model/feats_v12v2/bear1
    stop {
        training_iteration = 250
    }
    config = ${old_envconf_v29_feats_v12v1_bear1_movev4} ${train_v5v7_sqd}
}

#######################################################################################
### под статью 2 блок (12 лучей + 30 динамических)
#######################################################################################



ppo_e29_b1_f14_ar = ${ppo_dv1}  {
    local_dir: /s/ls4/users/slava1195/rl_rob/RL_robotSim/results/FollowerContinuous_paper/env29/PPO/default_model/feats_v14/bear1
    stop {
        training_iteration = 250
    }
    config = ${old_envconf_v29_feats_v14_bear1_around} ${train_v5v7_sqd}
}

ppo_e29_b1_f14_mv4 = ${ppo_dv1}  {
    local_dir: /s/ls4/users/slava1195/rl_rob/RL_robotSim/results/FollowerContinuous_paper/env29/PPO/default_model/feats_v14/bear1
    stop {
        training_iteration = 250
    }
    config = ${old_envconf_v29_feats_v14_bear1_movev4} ${train_v5v7_sqd}
}

#############

ppo_e29_b2_f14_ar = ${ppo_dv1}  {
    local_dir: /s/ls4/users/slava1195/rl_rob/RL_robotSim/results/FollowerContinuous_paper/env29/PPO/default_model/feats_v14/bear2
    stop {
        training_iteration = 250
    }
    config = ${old_envconf_v29_feats_v14_bear2_around} ${train_v5v7_sqd}
}

ppo_e29_b2_f14_mv4 = ${ppo_dv1}  {
    local_dir: /s/ls4/users/slava1195/rl_rob/RL_robotSim/results/FollowerContinuous_paper/env29/PPO/default_model/feats_v14/bear2
    stop {
        training_iteration = 250
    }
    config = ${old_envconf_v29_feats_v14_bear2_movev4} ${train_v5v7_sqd}
}



#######################################################################################
### тест компас (12 лучей + 24 с накоплением) envconf_v29_feats_v14VPC_bear1_around
#######################################################################################

# bear 1
ppo_e29_b1_f14VPC_ar = ${ppo_dv1}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous_test_sensors/env29/PPO/default_model/feats_v14VPC/bear1
    stop {
        training_iteration = 300
    }
    config = ${envconf_v29_feats_v14VPC_bear1_around} ${train_v5v7_sqd} ${def_m_prev}
}


#######################################################################################


ppo_e29_b1_f14VPC_mv4 = ${ppo_dv1}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous_test_sensors/env29/PPO/default_model/feats_v14VPC/bear1
    stop {
        training_iteration = 300
    }
    config = ${envconf_v29_feats_v14VPC_bear1_mv4} ${train_v5v7_sqd} ${def_m_prev}
}

ppo_e29_b2_f14VPC_ar = ${ppo_dv1}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous_test_sensors/env29/PPO/default_model/feats_v14VPC/bear2
    stop {
        training_iteration = 300
    }
    config = ${envconf_v29_feats_v14VPC_bear2_around} ${train_v5v7_sqd} ${def_m_prev}
}

ppo_e29_b2_f14VPC_mv4 = ${ppo_dv1}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous_test_sensors/env29/PPO/default_model/feats_v14VPC/bear2
    stop {
        training_iteration = 300
    }
    config = ${envconf_v29_feats_v14VPC_bear2_mv4} ${train_v5v7_sqd} ${def_m_prev}
}

ppo_e29_b2_f14VPC_mv4_mtransv4v5_tv5v16 = ${ppo_dv1}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous_test_sensors/env29/PPO/trans/feats_v14VPC/bear2
    stop {
        training_iteration = 300
    }
    config = ${envconf_v29_feats_v14VPC_bear2_mv4} ${train_v5v16_ppo} ${my_transformer_model_v4v5} 
}

ppo_e29_b2_f14VPC_mv4_tv5v16 = ${ppo_dv1}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous_test_sensors/env29/PPO/default_model/feats_v14VPC/bear2
    stop {
        training_iteration = 300
    }
    config = ${envconf_v29_feats_v14VPC_bear2_mv4} ${train_v5v16_ppo} ${def_m_prev} 
}

ppo_e29v2_b2_f14VPC_mv4 = ${ppo_dv1}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous_test_sensors/env29v2/PPO/default_model/feats_v14VPC/bear2
    stop {
        training_iteration = 300
    }
    config = ${envconf_v29v2_feats_v14VPC_bear2_mv4} ${train_v5v7_sqd} ${def_m_prev}
}
ppo_e29v2_b2_f14VPC_mv4_mtransv4v5_tv5v16 = ${ppo_dv1}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous_test_sensors/env29v2/PPO/trans/feats_v14VPC/bear2
    stop {
        training_iteration = 300
    }
    config = ${envconf_v29v2_feats_v14VPC_bear2_mv4} ${train_v5v16_ppo} ${my_transformer_model_v4v5} 
}

ppo_e29v2_b2_f14VPC_mv4_tv5v20 = ${ppo_dv1}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous_test_sensors/env29v2/PPO/default_model/feats_v14VPC/bear2
    stop {
        training_iteration = 300
    }
    config = ${envconf_v29v2_feats_v14VPC_bear2_mv4} ${train_v5v20} ${def_m_prev}
}
ppo_e29v2_b2_f14VPC_mv4_mtransv4v5_tv5v19 = ${ppo_dv1}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous_test_sensors/env29v2/PPO/trans/feats_v14VPC/bear2
    stop {
        training_iteration = 300
    }
    config = ${envconf_v29v2_feats_v14VPC_bear2_mv4} ${train_v5v19_ppo} ${my_transformer_model_v4v5} 
}

ppo_e29v3_b2_f14VPC_mv4 = ${ppo_dv1}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous_test_sensors/env29v3/PPO/default_model/feats_v14VPC/bear2
    stop {
        training_iteration = 300
    }
    config = ${envconf_v29v3_feats_v14VPC_bear2_mv4} ${train_v5v7_sqd} ${def_m_prev}
}
ppo_e29v4_b2_f14VPC_mv4 = ${ppo_dv1}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous_test_sensors/env29v4/PPO/default_model/feats_v14VPC/bear2
    stop {
        training_iteration = 300
    }
    config = ${envconf_v29v4_feats_v14VPC_bear2_mv4} ${train_v5v7_sqd} ${def_m_prev} 
}
ppo_e29v5_b2_f14VPC_mv4 = ${ppo_dv1}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous_test_sensors/env29v4/PPO/default_model/feats_v14VPC/bear2
    stop {
        training_iteration = 300
    }
    config = ${envconf_v29v5_feats_v14VPC_bear2_mv4} ${train_v5v7_sqd} ${def_m_prev} 
}
ppo_e29v3_b2_f14VPC_mv4_tv5v20 = ${ppo_dv1}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous_test_sensors/env29v3/PPO/default_model/feats_v14VPC/bear2
    stop {
        training_iteration = 300
    }
    config = ${envconf_v29v3_feats_v14VPC_bear2_mv4} ${train_v5v20} ${def_m_prev}
}
ppo_e29v3_b2_f14VPC_mv4_mtransv4v5_tv5v19 = ${ppo_dv1}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous_test_sensors/env29v3/PPO/trans/feats_v14VPC/bear2
    stop {
        training_iteration = 300
    }
    config = ${envconf_v29v3_feats_v14VPC_bear2_mv4} ${train_v5v19_ppo} ${my_transformer_model_v4v5} 
}
ppo_e29v6_b2_f17_mv4_mtransv4v5_tv5v19 = ${ppo_dv1}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous_test_sensors/env29v6/PPO/trans/feats_v15/bear2
    stop {
        training_iteration = 300
    }
    config = ${envconf_v29v6_feats_v17_bear2_mv4} ${train_v5v19_ppo} ${my_transformer_model_v4v5}
}

#######################################################################################
### Признаки - 2 сенсора с лучами, один реагирует только на корридор (с ориентацией или без), второй только на препятствия
#######################################################################################
ppo_e29_f15_b2mv4 = ${ppo_dv1}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous_test_sensors/e29_f15_b2mv4/PPO/default_model/feats_v15/bear2
    stop {
        training_iteration = 300
    }
    config = ${envconf_v29_feats_v15} ${train_v5v7_sqd} ${def_m_prev}
}
ppo_e29_f16_b2mv4 = ${ppo_dv1}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous_test_sensors/e29_f15_b2mv4/PPO/default_model/feats_v15/bear2
    stop {
        training_iteration = 300
    }
    config = ${envconf_v29_feats_v16} ${train_v5v7_sqd} ${def_m_prev}
}
#######################################################################################
### Реевская сетка, сравнение признаков. 
#######################################################################################
ppo_e29_v14VPC = ${ppo_dv1}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous_Prev/e29/PPO/v14VPC
    stop {
        training_iteration = 300
    }
    config = ${envconf_v29_feats_v14VPC_bear2_mv4} ${train_v5v7_sqd}
}
ppo_e29_fv15 = ${ppo_dv1}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous_Prev/e29/PPO/fv15
    stop {
        training_iteration = 300
    }
    config = ${envconf_v29_feats_v15} ${train_v5v7_sqd}
}
ppo_e29_fv16 = ${ppo_dv1}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous_Prev/e29/PPO/fv16
    stop {
        training_iteration = 300
    }
    config = ${envconf_v29_feats_v16} ${train_v5v7_sqd}
}
ppo_e29_fv17v1 = ${ppo_dv1}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous_Prev/e29/PPO/fv17v1
    stop {
        training_iteration = 300
    }
    config = ${envconf_v29_feats_v17v1} ${train_v5v7_sqd}
}
ppo_e29_fv17v2 = ${ppo_dv1}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous_Prev/e29/PPO/fv17v2
    stop {
        training_iteration = 300
    }
    config = ${envconf_v29_feats_v17v2} ${train_v5v7_sqd}
}

ppo_e29_fv17v3 = ${ppo_dv1}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous_Prev/e29/PPO/fv17v3
    stop {
        training_iteration = 300
    }
    config = ${envconf_v29_feats_v17v3} ${train_v5v7_sqd}
}

ppo_e29_fv17v4 = ${ppo_dv1}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous_Prev/e29/PPO/fv17v4
    stop {
        training_iteration = 300
    }
    config = ${envconf_v29_feats_v17v4} ${train_v5v7_sqd}
}

ppo_e29_fv17v5 = ${ppo_dv1}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous_Prev/e29/PPO/fv17v5
    stop {
        training_iteration = 300
    }
    config = ${envconf_v29_feats_v17v5} ${train_v5v7_sqd}
}

ppo_e29_fv17v6 = ${ppo_dv1}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous_Prev/e29/PPO/fv17v6
    stop {
        training_iteration = 300
    }
    config = ${envconf_v29_feats_v17v6} ${train_v5v7_sqd}
}

#######################################################################################
### Приближаем к газебо
#######################################################################################
ppo_e30_t5v7 = ${ppo_dv1}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous_Prev/e30/PPO/
    stop {
        training_iteration = 300
    }
    config = ${envconf_v30_f1} ${train_v5v7_sqd}
    restore = /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous_Prev/e30/PPO/ppo_e30_t5v7/PPO_continuous-grid_3a1e4_00000_0_2023-09-13_05-57-08/checkpoint_000145/checkpoint-145
}
ppo_e30v1_t5v7 = ${ppo_dv1}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous_Prev/e30v1/PPO/
    stop {
        training_iteration = 300
    }
    config = ${envconf_v30v1_f1} ${train_v5v7_sqd}
    restore = /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous_Prev/e30v1/PPO/ppo_e30v1_t5v7/PPO_continuous-grid_3a1e4_00001_1_2023-09-13_05-57-41/checkpoint_000145/checkpoint-145
}
ppo_e30v2_t5v7 = ${ppo_dv1}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous_Prev/e30v2/PPO/
    stop {
        training_iteration = 300
    }
    config = ${envconf_v30v2_f1} ${train_v5v7_sqd}
    restore = /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous_Prev/e30v2/PPO/ppo_e30v2_t5v7/PPO_continuous-grid_3a1e4_00002_2_2023-09-13_05-57-59/checkpoint_000150/checkpoint-150
}
ppo_e30_f1v2_t5v7 = ${ppo_dv1}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous_Prev/e30/PPO/
    stop {
        training_iteration = 300
    }
    config = ${envconf_v30_f1v2} ${train_v5v7_sqd}
    restore = /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous_Prev/e30/PPO/ppo_e30_f1v2_t5v7/PPO_continuous-grid_3c1bc_00000_0_2023-09-12_21-43-16/checkpoint_000135/checkpoint-135
}
ppo_e30_f1v3_t5v7 = ${ppo_dv1}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous_Prev/e30/PPO/
    stop {
        training_iteration = 300
    }
    config = ${envconf_v30_f1v3} ${train_v5v7_sqd}
    restore = /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous_Prev/e30/PPO/ppo_e30_f1v3_t5v7/PPO_continuous-grid_3c1bc_00001_1_2023-09-12_21-43-46/checkpoint_000135/checkpoint-135
}
ppo_e30_f1v3_t5v19 = ${ppo_dv1}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous_Prev/e30/PPO/
    stop {
        training_iteration = 300
    }
    config = ${envconf_v30_f1v3} ${train_v5v19_ppo}
}
ppo_e30_f1v2_t5v19_mtransv4v5 = ${ppo_dv1}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous_Prev/e30/PPO/
    stop {
        training_iteration = 300
    }
    config = ${envconf_v30_f1v2} ${train_v5v19_ppo} ${my_transformer_model_v4v5}
    restore = /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous_Prev/e30/PPO/ppo_e30_f1v2_t5v19_mtransv4v5/PPO_continuous-grid_41e56_00000_0_2023-09-12_21-43-25/checkpoint_000065/checkpoint-65
}
ppo_e30_f1v3_t5v19_mtransv4v5 = ${ppo_dv1}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous_Prev/e30/PPO/
    stop {
        training_iteration = 300
    }
    config = ${envconf_v30_f1v3} ${train_v5v19_ppo} ${my_transformer_model_v4v5}
    restore = /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous_Prev/e30/PPO/ppo_e30_f1v3_t5v19_mtransv4v5/PPO_continuous-grid_41e56_00001_1_2023-09-12_21-43-55/checkpoint_000060/checkpoint-60    
}
ppo_e30_f1v3_t5v7_mtransv4v5 = ${ppo_dv1}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous_Prev/e30/PPO/
    stop {
        training_iteration = 300
    }
    config = ${envconf_v30_f1v3} ${train_v5v7_sqd} ${my_transformer_model_v4v5}
    
}
