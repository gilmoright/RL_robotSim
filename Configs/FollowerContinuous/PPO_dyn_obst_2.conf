include "Environment_2.conf"
include "Exploration.conf"
include "Architecture.conf"
include "Architecture_2.conf"
include "Training.conf"

ppo_default {
    env = continuous-grid
    run = PPO
    local_dir = /s/ls4/users/slava1195/rl_rob/RL_robotSim/results/FollowerContinuous/dyn_obst/PPO/
    checkpoint_freq = 10
    stop {
        training_iteration = 400
    }
    config {
        num_gpus = 1
        timesteps_per_iteration = 1000
        num_workers = 4
        log_level = WARNING
        framework = torch
    }    
}



ppo_dv1 = ${ppo_default}  {
    checkpoint_freq = 5

    stop {
        training_iteration = 400
    }
    config {
        num_gpus = 1
        timesteps_per_iteration = 1000
        num_workers = 4
        log_level = WARNING
        framework = torch
    }
}




######################################

ppo_e28_b1_f14_m_def = ${ppo_dv1}  {
    local_dir: /s/ls4/users/slava1195/rl_rob/RL_robotSim/results/FollowerContinuous_2/env28/PPO/default_model/feats_v14
    stop {
        training_iteration = 250
    }
    config = ${envconf_v28_b1_feats_v14} ${train_v5v2_sqd} ${default_keras_model}
}

######################################

ppo_e28_b1_f14_prev5_m_def = ${ppo_dv1}  {
    local_dir: /s/ls4/users/slava1195/rl_rob/RL_robotSim/results/FollowerContinuous_2/env28/PPO/default_model/feats_v14
    stop {
        training_iteration = 250
    }
    config = ${envconf_v28_b1_feats_v14_prev5} ${train_v5v2_sqd} ${default_keras_model_prev}
}

ppo_e28_b1_f14_prev5_m_lstm = ${ppo_dv1}  {
    local_dir: /s/ls4/users/slava1195/rl_rob/RL_robotSim/results/FollowerContinuous_2/env28/PPO/default_model/feats_v14
    stop {
        training_iteration = 250
    }
    config = ${envconf_v28_b1_feats_v14_prev5} ${train_v5v2_sqd} ${lstm_model}
}


######################################
### test experiments for prev sensors
######################################

ppo_e28_b1_f14v2_prev5_m_def_v1 = ${ppo_dv1}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous_Prev/env28/PPO/default_model/feats_v14v2
    stop {
        training_iteration = 250
    }
    config = ${envconf_v28_b1_feats_v14v2_prev5} ${train_v5v2_sqd} ${def_m_prev}
}

ppo_e28_b2_f14v2_prev5_m_def_v1 = ${ppo_dv1}  {
    local_dir: /s/ls4/users/slava1195/rl_rob/RL_robotSim/results/FollowerContinuous_Prev/env28/PPO/default_model/feats_v14v2
    stop {
        training_iteration = 250
    }
    config = ${envconf_v28_b2_feats_v14v2_prev5} ${train_v5v2_sqd} ${def_m_prev}
}
ppo_e28_b1_f14v2_prev5_m_defv1_train_v5v16 = ${ppo_dv1}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous_Prev/env28/PPO/default_model/feats_v14v2/train
    stop {
        training_iteration = 250
    }
    config = ${envconf_v28_b1_feats_v14v2_prev5} ${train_v5v16_ppo} ${def_m_prev}
}

##########
#  LSTM  #
##########

ppo_e28_b1_f14v2_prev5_m_lstm_v1 = ${ppo_dv1}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous_Prev/env28/PPO/default_model/feats_v14v2
    stop {
        training_iteration = 250
    }
    config = ${envconf_v28_b1_feats_v14v2_prev5} ${train_v5v2_sqd} ${def_lstm_m_prev}
}

#################
#  Transformer  #
#################

ppo_e28_b1_f14v2_prev5_m_trans_v1 = ${ppo_dv1}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous_Prev/env28/PPO/default_model/feats_v14v2
    stop {
        training_iteration = 250
    }
    config = ${envconf_v28_b1_feats_v14v2_prev5} ${train_v5v2_sqd} ${my_transformer_model}
}

ppo_e28_b1_f14v2_prev5_m_trans_v4 = ${ppo_dv1}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous_Prev/env28/PPO/default_model/feats_v14v2
    stop {
        training_iteration = 250
    }
    config = ${envconf_v28_b1_feats_v14v2_prev5} ${train_v5v2_sqd} ${my_transformer_model_v4}
}
ppo_e28_b1_f14v2_prev5_m_trans_v4v2 = ${ppo_dv1}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous_Prev/env28/PPO/default_model/feats_v14v2
    stop {
        training_iteration = 250
    }
    config = ${envconf_v28_b1_feats_v14v2_prev5} ${train_v5v2_sqd} ${my_transformer_model_v4v2}
}
ppo_e28_b1_f14v2_prev5_m_trans_v4v3 = ${ppo_dv1}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous_Prev/env28/PPO/default_model/feats_v14v2
    stop {
        training_iteration = 250
    }
    config = ${envconf_v28_b1_feats_v14v2_prev5} ${train_v5v2_sqd} ${my_transformer_model_v4v3}
}
ppo_e28_b1_f14v2_prev5_m_trans_v4v4 = ${ppo_dv1}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous_Prev/env28/PPO/default_model/feats_v14v2
    stop {
        training_iteration = 250
    }
    config = ${envconf_v28_b1_feats_v14v2_prev5} ${train_v5v2_sqd} ${my_transformer_model_v4v4}
}

ppo_e28_b1_f14v2_prev5_m_raytrans = ${ppo_dv1}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous_Prev/env28/PPO/raytrans/feats_v14v2
    stop {
        training_iteration = 250
    }
    config = ${envconf_v28_b1_feats_v14v2_prev5} ${train_v5v2_sqd} ${model_raytrans_v1}
}


ppo_e28_b1_f14v2_prev5_m_transv4v2_train_v5v6sqd = ${ppo_dv1}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous_Prev/env28/PPO/trans/trans_v4v2/train/
    stop {
        training_iteration = 250
    }
    config = ${envconf_v28_b1_feats_v14v2_prev5} ${train_v5v6_sqd} ${my_transformer_model_v4v2}
}
ppo_e28_b1_f14v2_prev5_m_transv4v2_train_v5v10ppo = ${ppo_dv1}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous_Prev/env28/PPO/trans/trans_v4v2/train/
    stop {
        training_iteration = 250
    }
    config = ${envconf_v28_b1_feats_v14v2_prev5} ${train_v5v10_ppo} ${my_transformer_model_v4v2}
}
ppo_e28_b1_f14v2_prev5_m_transv4v2_train_v5v11sqd = ${ppo_dv1}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous_Prev/env28/PPO/trans/trans_v4v2/train/
    stop {
        training_iteration = 250
    }
    config = ${envconf_v28_b1_feats_v14v2_prev5} ${train_v5v11_sqd} ${my_transformer_model_v4v2} 
}
ppo_e28_b1_f14v2_prev5_m_transv4v2_train_v5v12ppo = ${ppo_dv1}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous_Prev/env28/PPO/trans/trans_v4v2/train/
    stop {
        training_iteration = 250
    }
    config = ${envconf_v28_b1_feats_v14v2_prev5} ${train_v5v12_ppo} ${my_transformer_model_v4v2} 
}

ppo_e28_b1_f14v2_prev5_m_transv4v2_train_v5v13ppo = ${ppo_dv1}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous_Prev/env28/PPO/trans/trans_v4v2/train/
    stop {
        training_iteration = 250
    }
    config = ${envconf_v28_b1_feats_v14v2_prev5} ${train_v5v13_ppo} ${my_transformer_model_v4v2} 
}

ppo_e28_b1_f14v2_prev5_m_transv4v2_train_v5v14ppo = ${ppo_dv1}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous_Prev/env28/PPO/trans/trans_v4v2/train/
    stop {
        training_iteration = 250
    }
    config = ${envconf_v28_b1_feats_v14v2_prev5} ${train_v5v14_ppo} ${my_transformer_model_v4v2} 
}

ppo_e28_b1_f14v2_prev5_m_transv4v2_train_v5v15ppo = ${ppo_dv1}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous_Prev/env28/PPO/trans/trans_v4v2/train/
    stop {
        training_iteration = 250
    }
    config = ${envconf_v28_b1_feats_v14v2_prev5} ${train_v5v15_ppo} ${my_transformer_model_v4v2} 
}

ppo_e28_b1_f14v2_prev5_m_transv4v2_train_v5v16ppo = ${ppo_dv1}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous_Prev/env28/PPO/trans/trans_v4v2/train/
    stop {
        training_iteration = 250
    }
    config = ${envconf_v28_b1_feats_v14v2_prev5} ${train_v5v16_ppo} ${my_transformer_model_v4v2} 
}

ppo_e28_b1_f14v2_prev5_m_transv4v2_train_v5v17ppo = ${ppo_dv1}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous_Prev/env28/PPO/trans/trans_v4v2/train/
    stop {
        training_iteration = 250
    }
    config = ${envconf_v28_b1_feats_v14v2_prev5} ${train_v5v17_ppo} ${my_transformer_model_v4v2} 
}
ppo_e28_b1_f14v2_prev5_m_transv4v5_train_v5v16ppo = ${ppo_dv1}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous_Prev/env28/PPO/trans/
    stop {
        training_iteration = 250
    }
    config = ${envconf_v28_b1_feats_v14v2_prev5} ${train_v5v16_ppo} ${my_transformer_model_v4v5} 
}


#####################
#  Ray Transformer  #
#####################


ppo_e28_b1_f14v2_prev5_m_raytrans = ${ppo_dv1}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous_Prev/env28/PPO/raytrans/feats_v14v2
    stop {
        training_iteration = 250
    }
    config = ${envconf_v28_b1_feats_v14v2_prev1} ${train_v5v2_sqd} ${model_raytrans_v1}
}

ppo_e28_b1_f14v2_prev5_m_raytrans_train_v5v16ppo = ${ppo_dv1}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous_Prev/env28/PPO/featsv14v2_raytrans/train
    stop {
        training_iteration = 250
    }
    config = ${envconf_v28_b1_feats_v14v2_prev1} ${train_v5v16_ppo} ${model_raytrans_v1} 
}


####################
#    test modify   #
####################

ppo_e28_b2_f14v2_prev5_m_def_v1_test_mody = ${ppo_dv1}  {
    local_dir: /s/ls4/users/slava1195/rl_rob/RL_robotSim/results/FollowerContinuous_Prev/env28/PPO/default_model/feats_v14v2
    stop {
        training_iteration = 300
    }
    config = ${envconf_v28_b2_feats_v14v2_prev5_test_mody} ${train_v5v7_sqd} ${def_m_prev_v2}
}

############
# BI LSTM  #
############

ppo_e28_b2_f14v2_prev5_m_bi_lstm_v2_low = ${ppo_dv1}  {
    local_dir: /s/ls4/users/slava1195/rl_rob/RL_robotSim/results/FollowerContinuous_Prev/env28/PPO/default_model/feats_v14v2
    stop {
        training_iteration = 250
    }
    config = ${envconf_v28_b2_feats_v14v2_prev5_test_mody_low} ${train_v5v7_sqd} ${bi_lstm_v2_m_prev}
}

ppo_e28_b2_f14v2_prev5_m_bi_lstm_v2 = ${ppo_dv1}  {
    local_dir: /s/ls4/users/slava1195/rl_rob/RL_robotSim/results/FollowerContinuous_Prev/env28/PPO/default_model/feats_v14v2
    stop {
        training_iteration = 250
    }
    config = ${envconf_v28_b2_feats_v14v2_prev5_test_mody} ${train_v5v7_sqd} ${bi_lstm_v2_m_prev}
}



##################
# LSTM prev 20   #
##################

ppo_e28_b2_f14v2_prev20_m_lstm_v1 = ${ppo_dv1}  {
    local_dir: /s/ls4/users/slava1195/rl_rob/RL_robotSim/results/FollowerContinuous_Prev/env28/PPO/default_model/feats_v14v2
    stop {
        training_iteration = 250
    }
    config = ${envconf_v28_b2_feats_v14v2_prev20_test_mody} ${train_v5v7_sqd} ${def_lstm_m_prev}
}




#######################################################################################
### под статью 1 блок (12 лучей)
#######################################################################################


ppo_e29_stat_f12v1 = ${ppo_dv1}  {
    local_dir: /s/ls4/users/slava1195/rl_rob/RL_robotSim/results/FollowerContinuous_paper/env29/PPO/default_model/feats_v12v2/no_bear
    stop {
        training_iteration = 250
    }
    config = ${old_envconf_v29_feats_v12v1_stat} ${train_v5v7_sqd}
}

ppo_e29_b1_f12v1_ar = ${ppo_dv1}  {
    local_dir: /s/ls4/users/slava1195/rl_rob/RL_robotSim/results/FollowerContinuous_paper/env29/PPO/default_model/feats_v12v2/bear1
    stop {
        training_iteration = 250
    }
    config = ${old_envconf_v29_feats_v12v1_bear1_around} ${train_v5v7_sqd}
}

ppo_e29_b1_f12v1_mv4 = ${ppo_dv1}  {
    local_dir: /s/ls4/users/slava1195/rl_rob/RL_robotSim/results/FollowerContinuous_paper/env29/PPO/default_model/feats_v12v2/bear1
    stop {
        training_iteration = 250
    }
    config = ${old_envconf_v29_feats_v12v1_bear1_movev4} ${train_v5v7_sqd}
}

#######################################################################################
### под статью 2 блок (12 лучей + 30 динамических)
#######################################################################################



ppo_e29_b1_f14_ar = ${ppo_dv1}  {
    local_dir: /s/ls4/users/slava1195/rl_rob/RL_robotSim/results/FollowerContinuous_paper/env29/PPO/default_model/feats_v14/bear1
    stop {
        training_iteration = 250
    }
    config = ${old_envconf_v29_feats_v14_bear1_around} ${train_v5v7_sqd}
}

ppo_e29_b1_f14_mv4 = ${ppo_dv1}  {
    local_dir: /s/ls4/users/slava1195/rl_rob/RL_robotSim/results/FollowerContinuous_paper/env29/PPO/default_model/feats_v14/bear1
    stop {
        training_iteration = 250
    }
    config = ${old_envconf_v29_feats_v14_bear1_movev4} ${train_v5v7_sqd}
}

#############

ppo_e29_b2_f14_ar = ${ppo_dv1}  {
    local_dir: /s/ls4/users/slava1195/rl_rob/RL_robotSim/results/FollowerContinuous_paper/env29/PPO/default_model/feats_v14/bear2
    stop {
        training_iteration = 250
    }
    config = ${old_envconf_v29_feats_v14_bear2_around} ${train_v5v7_sqd}
}

ppo_e29_b2_f14_mv4 = ${ppo_dv1}  {
    local_dir: /s/ls4/users/slava1195/rl_rob/RL_robotSim/results/FollowerContinuous_paper/env29/PPO/default_model/feats_v14/bear2
    stop {
        training_iteration = 250
    }
    config = ${old_envconf_v29_feats_v14_bear2_movev4} ${train_v5v7_sqd}
}



#######################################################################################
### тест компас (12 лучей + 24 с накоплением) envconf_v29_feats_v14VPC_bear1_around
#######################################################################################

# bear 1
ppo_e29_b1_f14VPC_ar = ${ppo_dv1}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous_test_sensors/env29/PPO/default_model/feats_v14VPC/bear1
    stop {
        training_iteration = 300
    }
    config = ${envconf_v29_feats_v14VPC_bear1_around} ${train_v5v7_sqd} ${def_m_prev}
}


#######################################################################################


ppo_e29_b1_f14VPC_mv4 = ${ppo_dv1}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous_test_sensors/env29/PPO/default_model/feats_v14VPC/bear1
    stop {
        training_iteration = 300
    }
    config = ${envconf_v29_feats_v14VPC_bear1_mv4} ${train_v5v7_sqd} ${def_m_prev}
}

ppo_e29_b2_f14VPC_ar = ${ppo_dv1}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous_test_sensors/env29/PPO/default_model/feats_v14VPC/bear2
    stop {
        training_iteration = 300
    }
    config = ${envconf_v29_feats_v14VPC_bear2_around} ${train_v5v7_sqd} ${def_m_prev}
}

ppo_e29_b2_f14VPC_mv4 = ${ppo_dv1}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous_test_sensors/env29/PPO/default_model/feats_v14VPC/bear2
    stop {
        training_iteration = 300
    }
    config = ${envconf_v29_feats_v14VPC_bear2_mv4} ${train_v5v7_sqd} ${def_m_prev}
}

ppo_e29_b2_f14VPC_mv4_mtransv4v5_tv5v16 = ${ppo_dv1}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous_test_sensors/env29/PPO/trans/feats_v14VPC/bear2
    stop {
        training_iteration = 300
    }
    config = ${envconf_v29_feats_v14VPC_bear2_mv4} ${train_v5v16_ppo} ${my_transformer_model_v4v5} 
}

ppo_e29_b2_f14VPC_mv4_tv5v16 = ${ppo_dv1}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous_test_sensors/env29/PPO/default_model/feats_v14VPC/bear2
    stop {
        training_iteration = 300
    }
    config = ${envconf_v29_feats_v14VPC_bear2_mv4} ${train_v5v16_ppo} ${def_m_prev} 
}