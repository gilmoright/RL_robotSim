Follower_v0:
    env: mini-grid
    run: PPO
    local_dir: /media/grartem/B7DB5B36121B73AA/Projects/RL_robots/RL_robotSim/results
    checkpoint_freq: 2
    stop:
        training_iteration: 50
        episode_reward_mean: 50        
    config:
        # Works for both torch and tf.
        env_config:
            name: MiniGrid-FollowTheLeader-cycle_all_strats-20x20-v0
            framestack: 5
        #framework: tf2
        num_gpus: 1
        timesteps_per_iteration: 10000

        # === Model ===
        num_workers: 2
        model: {
            #custom_model: MyFCNet,
            conv_filters: [[128, [4, 4], 1], [64, [3, 3], 1], [256, [35, 7], 1]], # last should have same output shape as the input data
            fcnet_hiddens: [64, 64],
            fcnet_activation: relu,
            no_final_linear: True
        }
        gamma: 0.99
        lr: .00001
        #learning_starts: 1000
        #buffer_size: 50000
        batch_mode: complete_episodes
        #rollout_fragment_length: 8
        train_batch_size: 10000
        # === Optimization ===
        #learning_starts: 500
        #rollout_fragment_length: 1

        # === Replay buffer ===
        #buffer_size: 10000
        #prioritized_replay: True
        #prioritized_replay_alpha: 0.6
        #prioritized_replay_beta: 0.4
        #prioritized_replay_eps: 0.000001
        #clip_rewards: False
        